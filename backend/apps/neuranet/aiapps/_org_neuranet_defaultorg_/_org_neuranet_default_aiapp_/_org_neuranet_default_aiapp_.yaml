# This YAML file is the core of any AI application. The ID in the file, the file name and the hosting folder must
# match. The file documents rest of the commands and syntax.

---
id: _org_neuranet_default_aiapp_            # the AI application name / ID
interface:                                  # the interface details
  type: enterpriseassist                    # this is for the frontend can be chat, translate or search interfaces
  label: AI assistant                       # the label for the app icon on the UI
  icon: data:image/svg+xml;base64,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
endpoint: llmflow                           # the API endpoint - usually llmflow
users: ["*"]                                # the * means all users, else must be an array of user IDs
api_uploads_cms_path: uploads               # where files are uploaded by index, unindex APIs

# all flows are sequence of commands which follow the same syntax - command, in, out - in is the input
# to the command, out is the variable holding the output and name points to the command module and entry
# point. the command sytax is documented below as well.

pregen_flow: 
  - command: rephrasedoc.generate           # module and entry function can be used using module.entry
    in: 
      label: Summary

      prompt: |
        Summarize the document below in simple langauage in no more than {{{words}}} words.
        {{{fragment}}}
        The summary is
      prompt_zh: |
        用不超过 {{{words}}} 个单词的简单语言总结下面的文档。
        {{{fragment}}}
        总结是
      prompt_ja: |
        以下の文書を簡単な言語で {{{words}}} 語以内に要約してください。
        {{{fragment}}}
        概要は次のとおりです
      prompt_hi: |
        नीचे दिए गए दस्तावेज़ को सरल भाषा में {{{words}}} से कम शब्दों में सारांशित करें।
        {{{टुकड़ा}}}
        सारांश है

      models: 
        - name: simplellm-gpt35-turbo
          type: chat
          model_overrides:                  # this allows us to override model params on a per AI app basis, can be a nested path e.g. driver.host if we are calling API at a different host name etc          
            read_ai_response_from_samples: true
        - name: embedding-openai-ada002
          type: embeddings
          model_overrides:                      
            read_ai_response_from_samples: true
      words_promptparam: 700
      pathid: summary
      encoding: utf8

  - command: rephrasedoc                    # entry function name is skipped as the default is generate anyways
    in: 
      label: Rephrased

      prompt: |                             # these can be prompt, prompt_docISOLanguage, prompt_fragment_fragmentISOLanguage
        Infer the document and rephrase it in a more generic context that most people without expertise or knowledge can understand.
        {{{fragment}}}
      prompt_zh: |
        文書を推測し、専門知識や知識を持たないほとんどの人が理解できる、より一般的な文脈で言い換えます。
        {{{fragment}}}
      prompt_ja: |
        文書を推測し、専門知識や知識を持たないほとんどの人が理解できる、より一般的な文脈で言い換えます。
        {{{fragment}}}
      prompt_hi: |
        दस्तावेज़ का अनुमान लगाएं और इसे अधिक सामान्य संदर्भ में दोबारा लिखें जिसे विशेषज्ञता या ज्ञान के बिना अधिकांश लोग समझ सकें।
        {{{fragment}}}

      models: 
        - name: simplellm-gpt35-turbo
          type: chat
          model_overrides:                  # this allows us to override model params on a per AI app basis, can be a nested path e.g. driver.host if we are calling API at a different host name etc          
            read_ai_response_from_samples: true
        - name: embedding-openai-ada002
          type: embeddings
          model_overrides:                      
            read_ai_response_from_samples: true
      pathid: reworded
      encoding: utf8


llm_flow:   
  - command: doctfidfsearch.search          # only for Chinese and Japanese languages, the condition below ensures that
    condition_js: |
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang("{{{query}}}"); if ((lang == "zh") || (lang == "ja")) return true; else return false;
    in: 
      query: "{{{query}}}"                  # inbuilt variable contains the user's query
      metadata: null
      topK_tfidf: 3
      cutoff_score_tfidf: 0.75
      topK_vectors: 3
      min_distance_vectors: 0
      brainid: "{{{aiappid}}}"              # inbuilt variable contains the ai app ID
    out: documentsfound

  - command: docvectorsearch.search         # for all languages except Chinese and Japanese, the condition below 
    condition_js: |
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang("{{{query}}}"); if ((lang == "zh") || (lang == "ja")) return false; else return true;
    in: 
      query: "{{{query}}}"
      topK_tfidf: 3
      cutoff_score_tfidf: 0.75
      topK_vectors: 3
      min_distance_vectors: 0
      embeddings_model: 
        name: embedding-openai-ada002
        model_overrides:                    
          read_ai_response_from_samples: true
      brainid: "{{{aiappid}}}"
    out: documentsfound

  - command: llm_history_chat               # default function entry is answer so entry function name is skipped
    in: 
      session_id: "{{{request.session_id}}}" # request is inbuilt variable contains user's request params

      prompt_for_question_rephrasing_noinflate: |
        Given the following conversation and a question, rephrase the question to include all relevant keywords and context from the conversation.
        Conversation:
        {{#session}}
        {{{role}}}: {{{content}}}
        {{/session}}

        Question: {{{question}}}

        The standalone question is:
      prompt_for_question_rephrasing_zh_noinflate: |
        给定以下对话和问题，重新表述问题以包含对话中的所有相关关键字和上下文。
        对话：
        {{#session}}
        {{{role}}}: {{{content}}}
        {{/session}}

        问题：{{{question}}}

        独立的问题是：
      prompt_for_question_rephrasing_ja_noinflate: |
        次の会話と質問がある場合、会話の関連するキーワードとコンテキストをすべて含めて質問を言い換えます。
        会話：
        {{#session}}
        {{{role}}}: {{{content}}}
        {{/session}}

        質問: {{{question}}}

        独立した質問は次のとおりです:
      prompt_for_question_rephrasing_hi_noinflate: |
        निम्नलिखित वार्तालाप और एक प्रश्न को देखते हुए, वार्तालाप से सभी प्रासंगिक कीवर्ड और संदर्भ को शामिल करने के लिए प्रश्न को दोबारा लिखें।
        बातचीत:
        {{#session}}
        {{{role}}}: {{{content}}}
        {{/session}}

        प्रश्न: {{{question}}

        स्टैंडअलोन प्रश्न यह है:
      question: "{{{query}}}"
      rephrasequestion: true

      documents_js: return documentsfound   # the _js means the value of this property is the inline JS code

      prompt_noinflate: |                   # means do not inflate this at the flow engine - the calling command will use it as is
        Answer the following question only using the documents provided below.
        Question:
        {{{question}}}

        Documents:
        {{#documents}}
        {{{content}}}

        {{/documents}}

        The answer is:
      prompt_zh_noinflate: |                   # means do not inflate this at the flow engine - the calling command will use it as is
        仅使用下面提供的文件回答以下问题。
        问题：
        {{{question}}}

        文件：
        {{#documents}}
        {{{content}}}

        {{/documents}}

        答案是：
      prompt_ja_noinflate: |                   
        以下に提供される文書のみを使用して、次の質問に答えてください。
        質問：
        {{{question}}}

        書類:
        {{#documents}}
        {{{content}}}

        {{/documents}}

        答えは次のとおりです:
      prompt_hi_noinflate: |                   # means do not inflate this at the flow engine - the calling command will use it as is
        निम्नलिखित प्रश्न का उत्तर केवल नीचे दिए गए दस्तावेज़ों का उपयोग करके दें।
        सवाल:
        {{{question}}}

        दस्तावेज़:
        {{#documents}}
        {{{content}}}

        {{/documents}}

        जवाब है:

      model: 
        name: chat-knowledgebase-gpt35-turbo
        model_overrides: 
          read_ai_response_from_samples: true
    out: airesponse                         # the final response must output to this property - airesponse for LLM flows


docsearch_flow:
  - command: doctfidfsearch.search          # only for Chinese and Japanese languages, the condition below ensures that
    condition_js: |
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang("{{{query}}}"); if ((lang == "zh") || (lang == "ja")) return true; else return false;
    in: 
      query: "{{{query}}}"                  # inbuilt variable contains the user's query
      metadata: null
      topK_tfidf: 3
      cutoff_score_tfidf: 0.75
      topK_vectors: 3
      min_distance_vectors: 0
      brainid: "{{{aiappid}}}"              # inbuilt variable contains the ai app ID
    out: airesponse.documents

  - command: docvectorsearch.search         # for all languages except Chinese and Japanese, the condition below 
    condition_js: |
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang("{{{query}}}"); if ((lang == "zh") || (lang == "ja")) return false; else return true;
    in: 
      query: "{{{query}}}"
      topK_tfidf: 3
      cutoff_score_tfidf: 0.75
      topK_vectors: 3
      min_distance_vectors: 0
      embeddings_model: 
        name: embedding-openai-ada002
        model_overrides:                    
          read_ai_response_from_samples: false
      brainid: "{{{aiappid}}}"
    out: airesponse.documents


modules: 
  llm_history_chat: llm_history_chat.js
